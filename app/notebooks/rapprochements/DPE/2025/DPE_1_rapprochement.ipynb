{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapprochement DPE juillet 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecols = ['numero_dpe', 'identifiant_ban', 'code_postal_ban', 'code_postal_brut', 'id_rnb', 'provenance_id_rnb']\n",
    "dtype={'numero_dpe': 'string', 'identifiant_ban': 'string', 'code_postal_ban': 'string', 'code_postal_brut': 'string', 'id_rnb': 'string', 'provenance_id_rnb': 'string'}\n",
    "\n",
    "# usecols = ['numero_dpe', 'id_rnb', 'provenance_id_rnb']\n",
    "# dtype={'numero_dpe': 'string', 'id_rnb': 'string', 'provenance_id_rnb': 'string'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tertiaire = pd.read_csv('notebooks/rapprochements/DPE/2025/data/dpe01tertiaire.csv', sep=',', usecols=usecols, dtype=dtype)\n",
    "df_tertiaire['file'] = 'tertiaire'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_existant = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnotebooks/rapprochements/DPE/2025/data/dpe03existant.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df_existant[\u001b[33m'\u001b[39m\u001b[33mfile\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m'\u001b[39m\u001b[33mexistant\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/lib/python3.13/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:2053\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:334\u001b[39m, in \u001b[36mgetstate\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "df_existant = pd.read_csv('notebooks/rapprochements/DPE/2025/data/dpe03existant.csv', sep=',', usecols=usecols, dtype=dtype)\n",
    "df_existant['file'] = 'existant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neuf = pd.read_csv('notebooks/rapprochements/DPE/2025/data/dpe02neuf.csv', sep=',', usecols=usecols, dtype=dtype)\n",
    "df_neuf['file'] = 'neuf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_tertiaire, df_neuf, df_existant])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13742029, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numero_dpe</th>\n",
       "      <th>id_rnb</th>\n",
       "      <th>provenance_id_rnb</th>\n",
       "      <th>code_postal_ban</th>\n",
       "      <th>identifiant_ban</th>\n",
       "      <th>code_postal_brut</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2269T2615953W</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>69440</td>\n",
       "      <td>69228_0086_00707</td>\n",
       "      <td>69440</td>\n",
       "      <td>tertiaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2313T1646022S</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>13360</td>\n",
       "      <td>13086_0035_00008</td>\n",
       "      <td>13360</td>\n",
       "      <td>tertiaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2404T3934296Y</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>04220</td>\n",
       "      <td>04197_0231</td>\n",
       "      <td>04220</td>\n",
       "      <td>tertiaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2394T2686905U</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>94420</td>\n",
       "      <td>94059_0530_00165</td>\n",
       "      <td>94420</td>\n",
       "      <td>tertiaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2360T0127880L</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>60650</td>\n",
       "      <td>60073_0075_00007</td>\n",
       "      <td>60650</td>\n",
       "      <td>tertiaire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      numero_dpe id_rnb provenance_id_rnb code_postal_ban   identifiant_ban  \\\n",
       "0  2269T2615953W   <NA>              <NA>           69440  69228_0086_00707   \n",
       "1  2313T1646022S   <NA>              <NA>           13360  13086_0035_00008   \n",
       "2  2404T3934296Y   <NA>              <NA>           04220        04197_0231   \n",
       "3  2394T2686905U   <NA>              <NA>           94420  94059_0530_00165   \n",
       "4  2360T0127880L   <NA>              <NA>           60650  60073_0075_00007   \n",
       "\n",
       "  code_postal_brut       file  \n",
       "0            69440  tertiaire  \n",
       "1            13360  tertiaire  \n",
       "2            04220  tertiaire  \n",
       "3            94420  tertiaire  \n",
       "4            60650  tertiaire  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# create 100 subfiles in the dpe_existant folder, using the number of rows in the dataframe\n",
    "for i in range(0, 100):\n",
    "    df.iloc[i*df.shape[0]//100:(i+1)*df.shape[0]//100].to_csv(f'notebooks/rapprochements/DPE/2025/sub_files/dpe-{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file 0\n",
      "processing file 1\n",
      "processing file 2\n",
      "processing file 3\n",
      "processing file 4\n",
      "processing file 5\n",
      "processing file 6\n",
      "processing file 7\n",
      "processing file 8\n",
      "processing file 9\n",
      "processing file 10\n",
      "processing file 11\n",
      "processing file 12\n",
      "processing file 13\n",
      "processing file 14\n",
      "processing file 15\n",
      "processing file 16\n",
      "processing file 17\n",
      "processing file 18\n",
      "processing file 19\n",
      "processing file 20\n",
      "processing file 21\n",
      "processing file 22\n",
      "processing file 23\n",
      "processing file 24\n",
      "processing file 25\n",
      "processing file 26\n",
      "processing file 27\n",
      "processing file 28\n",
      "processing file 29\n",
      "processing file 30\n",
      "processing file 31\n",
      "processing file 32\n",
      "processing file 33\n",
      "processing file 34\n",
      "processing file 35\n",
      "processing file 36\n",
      "processing file 37\n",
      "processing file 38\n",
      "processing file 39\n",
      "processing file 40\n",
      "processing file 41\n",
      "processing file 42\n",
      "processing file 43\n",
      "processing file 44\n",
      "processing file 45\n",
      "processing file 46\n",
      "processing file 47\n",
      "processing file 48\n",
      "processing file 49\n",
      "processing file 50\n",
      "processing file 51\n",
      "processing file 52\n",
      "processing file 53\n",
      "processing file 54\n",
      "processing file 55\n",
      "processing file 56\n",
      "processing file 57\n",
      "processing file 58\n",
      "processing file 59\n",
      "processing file 60\n",
      "processing file 61\n",
      "processing file 62\n",
      "processing file 63\n",
      "processing file 64\n",
      "processing file 65\n",
      "processing file 66\n",
      "processing file 67\n",
      "processing file 68\n",
      "processing file 69\n",
      "processing file 70\n",
      "processing file 71\n",
      "processing file 72\n",
      "processing file 73\n",
      "processing file 74\n",
      "processing file 75\n",
      "processing file 76\n",
      "processing file 77\n",
      "processing file 78\n",
      "processing file 79\n",
      "processing file 80\n",
      "processing file 81\n",
      "processing file 82\n",
      "processing file 83\n",
      "processing file 84\n",
      "processing file 85\n",
      "processing file 86\n",
      "processing file 87\n",
      "processing file 88\n",
      "processing file 89\n",
      "processing file 90\n",
      "processing file 91\n",
      "processing file 92\n",
      "processing file 93\n",
      "processing file 94\n",
      "processing file 95\n",
      "processing file 96\n",
      "processing file 97\n",
      "processing file 98\n",
      "processing file 99\n"
     ]
    }
   ],
   "source": [
    "# le rapprochement\n",
    "\n",
    "import os\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "from django.db import connection\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import numpy as np\n",
    "\n",
    "def get_rnb_id(row):\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    if row['code_postal_ban'] != row['code_postal_brut']:\n",
    "        return []\n",
    "    \n",
    "    ban_id = row['identifiant_ban']\n",
    "\n",
    "    sql = f\"\"\"\n",
    "            with rnb_ids as (\n",
    "            select\n",
    "                rnb_id\n",
    "            from\n",
    "                batid_buildingaddressesreadonly bb\n",
    "            left join batid_building bb2 on\n",
    "                bb2.id = bb.building_id\n",
    "            where\n",
    "                address_id = '{ban_id}'\n",
    "                and ST_AREA(shape::geography) > 25)\n",
    "            select\n",
    "                array_agg(rnb_id)\n",
    "            from\n",
    "                rnb_ids;\n",
    "    \"\"\"\n",
    "    cursor.execute(sql)\n",
    "    result = cursor.fetchone()\n",
    "    return result[0] if result[0] is not None else []\n",
    "\n",
    "def execute(df):\n",
    "    df_copy = df.copy()\n",
    "    df_copy['rnb_id_rappro'] = df_copy.apply(get_rnb_id, axis=1)\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def process_sub_file(i):\n",
    "    print(f\"processing file {i}\")\n",
    "    if not os.path.exists(f'notebooks/rapprochements/DPE/2025/sub_files_results/dpe-{i}-result.csv'):\n",
    "        df_sub_file = pd.read_csv(f'notebooks/rapprochements/DPE/2025/sub_files/dpe-{i}.csv', sep=',')\n",
    "        max_workers = 50\n",
    "        dfs = np.array_split(df_sub_file, max_workers)\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            results_sub_file = executor.map(execute, dfs)\n",
    "            df_result = pd.concat(results_sub_file)\n",
    "            df_result.to_csv(f'notebooks/rapprochements/DPE/2025/sub_files_results/dpe-{i}-result.csv', index=False)\n",
    "\n",
    "for i in range(100):\n",
    "    process_sub_file(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2074/3264209841.py:4: DtypeWarning: Columns (1,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_result = pd.read_csv(f'notebooks/rapprochements/DPE/2025/sub_files_results/dpe-{i}-result.csv', usecols=['numero_dpe', 'file', 'rnb_id_rappro', 'id_rnb', 'provenance_id_rnb'])\n",
      "/tmp/ipykernel_2074/3264209841.py:4: DtypeWarning: Columns (1,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_result = pd.read_csv(f'notebooks/rapprochements/DPE/2025/sub_files_results/dpe-{i}-result.csv', usecols=['numero_dpe', 'file', 'rnb_id_rappro', 'id_rnb', 'provenance_id_rnb'])\n",
      "/tmp/ipykernel_2074/3264209841.py:4: DtypeWarning: Columns (1,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_result = pd.read_csv(f'notebooks/rapprochements/DPE/2025/sub_files_results/dpe-{i}-result.csv', usecols=['numero_dpe', 'file', 'rnb_id_rappro', 'id_rnb', 'provenance_id_rnb'])\n",
      "/tmp/ipykernel_2074/3264209841.py:4: DtypeWarning: Columns (1,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_result = pd.read_csv(f'notebooks/rapprochements/DPE/2025/sub_files_results/dpe-{i}-result.csv', usecols=['numero_dpe', 'file', 'rnb_id_rappro', 'id_rnb', 'provenance_id_rnb'])\n"
     ]
    }
   ],
   "source": [
    "# aggregation des sous fichiers de résultats en un seul\n",
    "dfs_result = []\n",
    "\n",
    "for i in range(100):\n",
    "    df_result = pd.read_csv(f'notebooks/rapprochements/DPE/2025/sub_files_results/dpe-{i}-result.csv', usecols=['numero_dpe', 'file', 'rnb_id_rappro', 'id_rnb', 'provenance_id_rnb'])\n",
    "    dfs_result.append(df_result)\n",
    "\n",
    "df_final = pd.concat(dfs_result)\n",
    "df_final['rnb_id_rappro'] = df_final['rnb_id_rappro'].apply(eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarde des résultats\n",
    "df_final.to_csv('notebooks/rapprochements/DPE/2025/results_DPE_RNB.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
